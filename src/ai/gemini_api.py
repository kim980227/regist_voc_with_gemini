# gemini_api.py
import google.generativeai as genai
import time
import os
import pandas as pd
import src.ai.prompt_builder as prompt_builder
from src.ai.api_usage_limiter import rate_limit_guard

REASON_LOG_PATH = "log/"

# config.pyì—ì„œ í•„ìš”í•œ ì „ì—­ ë³€ìˆ˜ë“¤ ì„í¬íŠ¸
from src.config.config import (
    GEMINI_MODEL, # GEMINI_MODELì€ ì—¬ê¸°ì„œ ì‚¬ìš©í•˜ì§€ë§Œ, configì—ì„œ ì´ˆê¸°í™”ë§Œ í•  ê²ƒ
)

def infer_voc_type_with_gemini(df_voc, voc_type_map, ):
    """
    Gemini ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ VOCìœ í˜•ì´ NaNì¸ ê²½ìš° ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ í•©ë‹ˆë‹¤.
    ì´ í•¨ìˆ˜ëŠ” GEMINI_MODELì„ ì§ì ‘ ì‚¬ìš©í•˜ë©°, config.pyì—ì„œ ë¯¸ë¦¬ ì´ˆê¸°í™”ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    """
    print("\nğŸ” Geminië¥¼ ì´ìš©í•œ VOCìœ í˜• ì¶”ë¡  ì‹œì‘")

    valid_types = list(voc_type_map.keys())
    updated_count = 0
    reasons = []
    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œë¥¼ í•¨ìˆ˜ í˜¸ì¶œ ì‹œì ì—ì„œ ë™ì ìœ¼ë¡œ ìƒì„±
    # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(REASON_LOG_PATH, exist_ok=True)
    # í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ 'YYYYMMDD_HHMMSS' í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
    timestamp = time.strftime("%Y%m%d_%H%M%S", time.localtime())
    reason_log_path = os.path.join(REASON_LOG_PATH, f"voc_infer_log_{timestamp}.txt")

    # 'VOCìœ í˜•' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì¶”ê°€ (DataFrameì´ ë¹„ì–´ìˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„)
    if 'VOCìœ í˜•' not in df_voc.columns:
        df_voc['VOCìœ í˜•'] = None # ë˜ëŠ” ì ì ˆí•œ ê¸°ë³¸ê°’

    # VOC ìœ í˜•ì´ NaNì¸ í–‰ë§Œ í•„í„°ë§í•˜ì—¬ ìˆœíšŒ
    for idx, row in df_voc[df_voc['VOCìœ í˜•'].isna()].iterrows():
        voc_content = str(row.get("VOCë‚´ìš©", "")).strip() # NaNì´ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ
        voc_action = str(row.get("ì¡°ì¹˜ê³„íš ë° ì§„í–‰ìƒí™©", "")).strip() # NaNì´ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ

        prompt = prompt_builder.build_voc_type_prompt(voc_content, voc_action, valid_types)

        try:
            # âœ… ì‚¬ìš©ëŸ‰ ì œí•œ ì²´í¬
            token_estimate = len(prompt) // 2 # ëŒ€ëµì ì¸ í† í° ìˆ˜ ê³„ì‚° (ë³´ìˆ˜ì  ì¶”ì •)
            rate_limit_guard(tokens_used=token_estimate)

            # ğŸ” Gemini API í˜¸ì¶œ
            response = GEMINI_MODEL.generate_content(prompt) # configì—ì„œ ì„í¬íŠ¸í•œ GEMINI_MODEL ì‚¬ìš©
            text = response.text.strip()

            # âœ… ê²°ê³¼ íŒŒì‹±
            predicted_type = next((t for t in valid_types if t in text), None)
            if predicted_type:
                df_voc.at[idx, 'VOCìœ í˜•'] = predicted_type
                updated_count += 1
                reason_line = f"[Excel í–‰ {idx + 2}] ì˜ˆì¸¡ëœ ìœ í˜•: {predicted_type} / ì´ìœ : {text}\n"
                reasons.append(reason_line)
                print(reason_line.strip())
            else:
                reason_line = f"[Excel í–‰ {idx + 2}] âŒ ìœ í˜• ì˜ˆì¸¡ ì‹¤íŒ¨ / ì‘ë‹µ: {text}\n"
                reasons.append(reason_line)
                print(reason_line.strip())
            time.sleep(1) # API í˜¸ì¶œ ê°„ ì§§ì€ ì§€ì—° ì¶”ê°€ (ê³¼ë„í•œ ìš”ì²­ ë°©ì§€)

        except RuntimeError as e: # rate_limit_guardì—ì„œ ë°œìƒì‹œí‚¤ëŠ” ì˜ˆì™¸
            reason_line = f"[Excel í–‰ {idx + 2}] âŒ Gemini í˜¸ì¶œ ì œí•œ: {e}\n"
            reasons.append(reason_line)
            print(reason_line.strip())
            break # ì œí•œì— ê±¸ë¦¬ë©´ ë” ì´ìƒ ì§„í–‰í•˜ì§€ ì•ŠìŒ
        except Exception as e:
            reason_line = f"[Excel í–‰ {idx + 2}] âŒ Gemini í˜¸ì¶œ ì˜¤ë¥˜: {e}\n"
            reasons.append(reason_line)
            print(reason_line.strip())

    print(f"âœ… VOCìœ í˜•ì´ ì—†ëŠ” {updated_count}ê±´ì— ëŒ€í•´ ìœ í˜•ì„ ì¶”ë¡ í•˜ì—¬ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤.")

    if reasons:
        with open(reason_log_path, "w", encoding="utf-8") as f:
            f.writelines(reasons)
        print(f"ğŸ“ ì¶”ë¡  ì´ìœ ëŠ” '{reason_log_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    return df_voc